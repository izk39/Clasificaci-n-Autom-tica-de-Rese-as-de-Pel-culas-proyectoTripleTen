# Clasificaci-n-Autom-tica-de-Rese-as-de-Pel-culas-proyectoTripleTen
Proyecto para desarrollar un modelo de clasificaci√≥n que detecte autom√°ticamente cr√≠ticas negativas en rese√±as de pel√≠culas de IMDB, este es un proyecto del bootcamp de TripleTen

üé¨ Film Junky Union ‚Äî Clasificaci√≥n Autom√°tica de Rese√±as de Pel√≠culas
Proyecto para desarrollar un modelo de clasificaci√≥n que detecte autom√°ticamente cr√≠ticas negativas en rese√±as de pel√≠culas de IMDB. La meta es alcanzar un valor F1 m√≠nimo de 0.85 para garantizar una detecci√≥n precisa.

üìÅ Archivo de datos
imdb_reviews.tsv: conjunto de datos con rese√±as etiquetadas.

review: texto de la rese√±a.

pos: etiqueta objetivo (0 = negativo, 1 = positivo).

ds_part: indica si la fila corresponde a entrenamiento o prueba.

üß™ Objetivo del proyecto
Cargar y preprocesar los datos textuales para su vectorizaci√≥n.

Realizar un an√°lisis exploratorio para entender la distribuci√≥n y posible desequilibrio de clases.

Entrenar al menos tres modelos diferentes de clasificaci√≥n para predecir la polaridad de las rese√±as.

Evaluar los modelos utilizando m√©tricas adecuadas, priorizando el F1-score.

Clasificar rese√±as escritas manualmente con los modelos entrenados y comparar resultados.

Analizar y explicar las diferencias en desempe√±o de los modelos.

Mantener un c√≥digo limpio, organizado y reproducible.

üõ†Ô∏è Proceso desarrollado
1. Preparaci√≥n y an√°lisis de datos
Carga y exploraci√≥n del archivo imdb_reviews.tsv.

An√°lisis exploratorio para detectar desequilibrio de clases y caracter√≠sticas del texto.

Limpieza y preprocesamiento del texto (tokenizaci√≥n, limpieza, vectorizaci√≥n).

2. Modelado predictivo
Definici√≥n y entrenamiento de al menos tres modelos, incluyendo:

Regresi√≥n log√≠stica

Potenciaci√≥n del gradiente (Gradient Boosting)

Otros modelos probados seg√∫n conveniencia

Evaluaci√≥n con el conjunto de prueba usando m√©tricas clave: precisi√≥n, recall y F1.

3. Evaluaci√≥n y conclusiones
Clasificaci√≥n de rese√±as escritas manualmente para validar modelos.

Comparaci√≥n detallada del rendimiento y explicaci√≥n de diferencias.

Discusi√≥n sobre hallazgos y recomendaciones.

‚ö†Ô∏è Nota sobre BERT
Aunque la plantilla incluye funciones para convertir textos en embeddings con BERT, el uso completo de BERT no es obligatorio debido a su alta demanda computacional y lentitud en CPU. Se puede usar para un subconjunto peque√±o para pruebas experimentales, siempre dejando claro en el c√≥digo.

üß† Herramientas utilizadas
Python (Pandas, NumPy, Scikit-learn)

Jupyter Notebook

T√©cnicas de NLP para preprocesamiento y vectorizaci√≥n

Evaluaci√≥n con m√©tricas est√°ndar para clasificaci√≥n binaria

‚úÖ Resultados esperados
Modelos entrenados que superen el umbral m√≠nimo de F1-score (0.85).

An√°lisis claro de la distribuci√≥n de clases y comportamiento del modelo.

C√≥digo reproducible y limpio, siguiendo buenas pr√°cticas.